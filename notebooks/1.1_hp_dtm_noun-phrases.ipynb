{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "introductory-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim import corpora, utils\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.models.wrappers import DtmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "impressed-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-hours",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "professional-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./../data/raw/training-subset.csv\", converters={'np': eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "controlling-qualification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7799, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exciting-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data[\"year\"].notnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "according-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"year\"] = data[\"year\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "corporate-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_cnt = data['year'].value_counts().rename_axis('year').reset_index(name='excerpt_count')\n",
    "dates_cnt.sort_values('year', inplace = True, ascending = True)\n",
    "time_seq = dates_cnt['excerpt_count'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "alternate-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #now we count the number of full texts in each years\n",
    "# dates_count = data.groupby(\"year\").agg(n_paragraphs = (\"fulltext\", \"size\"))\n",
    "# dates_count = dates_count.loc[dates_count['n_paragraphs'].ne(0)].reset_index()\n",
    "# dates_count[\"n_paragraphs\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "catholic-tokyo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7793"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time_seq = dates_count[\"n_paragraphs\"].to_list()\n",
    "sum(time_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-highway",
   "metadata": {},
   "source": [
    "# Dictionary and BOWs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "following-organization",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO:gensim.corpora.dictionary:built Dictionary(524452 unique tokens: ['Algerian opposition leaders', 'Balkan leader', 'Beijing rule', 'Belgrade last week', 'Belgrade military hospital']...) from 7793 documents (total 1069049 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524452 tokens overall\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary\n",
    "dictionary = corpora.Dictionary(data['np'])  \n",
    "print(f'{len(dictionary)} tokens overall') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "right-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:discarding 411507 tokens: [('Balkan leader', 1), ('Beijing rule', 1), ('Belgrade last week', 1), ('Belgrade military hospital', 1), ('Bosnian Serb headquarters', 1), ('Chinese prison', 1), ('Constable Glenn Schweyer', 1), ('EUROPE Official', 1), ('Garry Styles', 1), ('Julius Rose', 1)]...\n",
      "INFO:gensim.corpora.dictionary:keeping 112945 tokens which were in no less than 2 and no more than 7715 (=99.0%) documents\n",
      "DEBUG:gensim.corpora.dictionary:rebuilding dictionary, shrinking gaps\n",
      "INFO:gensim.corpora.dictionary:resulting dictionary: Dictionary(112945 unique tokens: ['Algerian opposition leaders', 'Chinese authorities', 'Education Minister Domingo Palermo', 'European defense policy', 'French newspaper Le Monde']...)\n",
      "DEBUG:gensim.corpora.dictionary:rebuilding dictionary, shrinking gaps\n"
     ]
    }
   ],
   "source": [
    "# now we'll filter the tokens that appear too frequently or are too rare\n",
    "dictionary.filter_extremes(no_below = 2, no_above = 0.99, keep_n=200000)\n",
    "dictionary.compactify()  # make token IDs sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "collective-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bows'] = data['np'].apply(dictionary.doc2bow)  # convert documents (list of tokens) to BOWs\n",
    "# print(data['bows'][0]) #what we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-exercise",
   "metadata": {},
   "source": [
    "# DTM model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-aspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.wrappers.dtmmodel:serializing temporary corpus to C:\\Users\\hryho\\AppData\\Local\\Temp\\2023e8_train-mult.dat\n",
      "INFO:gensim.corpora.bleicorpus:no word id mapping provided; initializing from corpus\n",
      "INFO:gensim.corpora.bleicorpus:storing corpus in Blei's LDA-C format into C:\\Users\\hryho\\AppData\\Local\\Temp\\2023e8_train-mult.dat\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'C:\\\\Users\\\\hryho\\\\AppData\\\\Local\\\\Temp\\\\2023e8_train-mult.dat', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "INFO:gensim.corpora.bleicorpus:saving vocabulary of 112945 words to C:\\Users\\hryho\\AppData\\Local\\Temp\\2023e8_train-mult.dat.vocab\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'C:\\\\Users\\\\hryho\\\\AppData\\\\Local\\\\Temp\\\\2023e8_train-mult.dat.vocab', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'C:\\\\Users\\\\hryho\\\\AppData\\\\Local\\\\Temp\\\\2023e8_train-seq.dat', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "INFO:gensim.models.wrappers.dtmmodel:training DTM with args --ntopics=20 --model=dtm  --mode=fit --initialize_lda=true --corpus_prefix=C:\\Users\\hryho\\AppData\\Local\\Temp\\2023e8_train --outname=C:\\Users\\hryho\\AppData\\Local\\Temp\\2023e8_train_out --alpha=0.01 --lda_max_em_iter=10 --lda_sequence_min_iter=6  --lda_sequence_max_iter=20 --top_chain_var=0.05 --rng_seed=0 \n",
      "INFO:gensim.models.wrappers.dtmmodel:Running command ['C:/github/tt-weights/models/bin/dtm-win64.exe', '--ntopics=20', '--model=dtm', '--mode=fit', '--initialize_lda=true', '--corpus_prefix=C:\\\\Users\\\\hryho\\\\AppData\\\\Local\\\\Temp\\\\2023e8_train', '--outname=C:\\\\Users\\\\hryho\\\\AppData\\\\Local\\\\Temp\\\\2023e8_train_out', '--alpha=0.01', '--lda_max_em_iter=10', '--lda_sequence_min_iter=6', '--lda_sequence_max_iter=20', '--top_chain_var=0.05', '--rng_seed=0']\n",
      "DEBUG:gensim.utils:COMMAND: () {'args': ['C:/github/tt-weights/models/bin/dtm-win64.exe', '--ntopics=20', '--model=dtm', '--mode=fit', '--initialize_lda=true', '--corpus_prefix=C:\\\\Users\\\\hryho\\\\AppData\\\\Local\\\\Temp\\\\2023e8_train', '--outname=C:\\\\Users\\\\hryho\\\\AppData\\\\Local\\\\Temp\\\\2023e8_train_out', '--alpha=0.01', '--lda_max_em_iter=10', '--lda_sequence_min_iter=6', '--lda_sequence_max_iter=20', '--top_chain_var=0.05', '--rng_seed=0'], 'stderr': -1}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = DtmModel(\n",
    "    dtm_path=\"C:/github/tt-weights/models/bin/dtm-win64.exe\",\n",
    "    corpus=data[\"bows\"].values,\n",
    "    time_slices=time_seq,\n",
    "    num_topics=20,\n",
    "    id2word=dictionary,\n",
    "    initialize_lda=True,\n",
    "    top_chain_var=0.05\n",
    ")\n",
    "finish = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "finish - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "improved-rouge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12163.771802186966"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finish - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/dtm-noun-phrases.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-width",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-windsor",
   "metadata": {},
   "source": [
    "# topic weights over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DtmModel.load(\"../models/dtm-noun-phrases.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_seq_d = dates_cnt.set_index(dates_cnt[\"year\"])[\"excerpt_count\"].to_dict()\n",
    "\n",
    "topics = {}\n",
    "for idx, year in enumerate(time_seq_d.keys()):\n",
    "    doc_topic, topic_term, doc_lengths, term_frequency, vocab = model.dtm_vis(time=idx,corpus=data['bows'])\n",
    "    topics[year] = doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(topics[2010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(topics[2010][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "directed-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_doc_index = 0\n",
    "# for year, time in zip(time_seq_d.keys(), time_seq):\n",
    "#     last_doc_index = first_doc_index + time\n",
    "#     topics[f\"{year}_seq\"] = topics[year][first_doc_index:last_doc_index]\n",
    "#     first_doc_index = first_doc_index + year_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_matrix = pd.DataFrame() # create a placeholder df\n",
    "for k, v in topics.items(): #iterate over keys and values in our dictionary with matrices\n",
    "    x = pd.DataFrame.from_records(v) #create a df from the current slice matrix\n",
    "    x['year_pub'] = k #create a column for year and assign the key value to it\n",
    "    doc_topic_matrix = pd.concat([doc_topic_matrix, x]) #now append to our placeholder df\n",
    "#let's see how it looks\n",
    "doc_topic_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_matrix.columns = [f\"topic_{c}\" if isinstance(c, int) else c for c in doc_topic_matrix.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_over_time = pd.concat([data, doc_topic_matrix.reset_index(drop = True)], axis = 1)\n",
    "topics_over_time.drop(columns = ['filename', 'year_pub'], inplace = True)\n",
    "\n",
    "# topics_over_time['year'] = pd.to_datetime(topics_over_time['year'], format = '%Y')\n",
    "topics_over_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_over_time = pd.melt(topics_over_time, id_vars = ['author', 'database', 'doi', \n",
    "                                                    'fulltext', 'np','place','pubtitle', 'title', 'url', \n",
    "                                                    'year', 'bows'], \n",
    "            value_vars = ['topic_0', 'topic_1', 'topic_2', 'topic_3', 'topic_4', 'topic_5', 'topic_6', \n",
    "                          'topic_7', 'topic_8', 'topic_9', 'topic_10', 'topic_11', 'topic_12', \n",
    "                          'topic_13', 'topic_14', 'topic_15', 'topic_16', 'topic_17', 'topic_18', 'topic_19', ],\n",
    "            var_name = 'topic_num',\n",
    "            value_name = 'topic_weight')\n",
    "topics_over_time.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [*topics.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_topics_by_time = {}\n",
    "for t, year in enumerate(years):\n",
    "    # since we have 20 topics - range(20)\n",
    "    topics = []\n",
    "    for n in range(20): \n",
    "        current_topic = model.show_topic(\n",
    "            topicid=n,\n",
    "            time=t,\n",
    "            topn=15 # top 15 most salient terms\n",
    "        )\n",
    "        topics.append(\n",
    "            # round probability of each word to three values 1.111\n",
    "            [(np.around(prob, 3), word) for prob, word in current_topic]\n",
    "        )\n",
    "    term_topics_by_time[year] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_term_matrix = pd.DataFrame(term_topics_by_time) # create a df from the dictionary \n",
    "topic_term_matrix.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_term_table = topic_term_matrix.T # we need to turn it\n",
    "topic_term_table['year'] = topic_term_table.index.astype(int) # create an index (now indexed by years)\n",
    "topic_term_table.reset_index(inplace = True, drop = True)\n",
    "topic_term_table.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_term_table.columns = [f\"topic_{c}\" if isinstance(c, int) else c for c in topic_term_table.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_term_table = pd.melt(topic_term_table, id_vars = 'year', \n",
    "                           value_vars = ['topic_0', 'topic_1', 'topic_2', 'topic_3', 'topic_4', \n",
    "                                         'topic_5', 'topic_6', 'topic_7', 'topic_8', 'topic_9', \n",
    "                                         'topic_10', 'topic_11', 'topic_12', 'topic_13', 'topic_14', \n",
    "                                         'topic_15', 'topic_16', 'topic_17', 'topic_18', 'topic_19'], \n",
    "                           var_name = 'topic_num', value_name = 'terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_term_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_over_time = topics_over_time.merge(topic_term_table, how = 'left', on = ['year', 'topic_num'])\n",
    "\n",
    "topics_over_time.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_over_time.drop(columns = ['bows', 'doi'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_over_time = topics_over_time.loc[topics_over_time[\"np\"].notnull()].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify(l):\n",
    "    return [f\"{str(prob)} {word}\" for prob, word in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_over_time[\"terms\"] = topics_over_time[\"terms\"].apply(simplify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_over_time.to_json(\n",
    "    \"../data/processed/noun-phrases-topics_over_time.json\", \n",
    "    lines=True,\n",
    "    orient=\"records\", \n",
    "    force_ascii=False, \n",
    "    date_format=\"iso\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-offering",
   "metadata": {},
   "source": [
    "# term weights over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for t, year in enumerate(years):\n",
    "    for n in range(20):\n",
    "        current_topic = model.show_topic(\n",
    "            topicid=n,\n",
    "            time=t,\n",
    "            topn=15 # top 15 most salient terms\n",
    "        )\n",
    "        topics.extend(\n",
    "            [list(term) + [year, n] for term in current_topic]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_by_time = pd.DataFrame(topics, columns = ['weight', 'term', 'year', 'topic n'])\n",
    "terms_by_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_by_time.to_csv(\"../data/processed/noun-phrases-terms_over_time.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_by_time.groupby([\"year\", \"topic n\"]).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
